{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f44f455a",
   "metadata": {},
   "outputs": [],
   "source": [
    "language = 'ja'\n",
    "import name_transliteration.filtering as filter\n",
    "import name_transliteration.cleansing as cleanse\n",
    "import name_transliteration.model_trainer_and_tester as model_trainer_and_tester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6dc75682",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/stream-2021-03-07T03:05:07.831679.gz\n",
      "./data/stream-2021-01-13T01:21:29.804195.gz\n",
      "./data/stream-2021-01-13T04:07:46.253913.gz\n",
      "./data/stream-2021-01-12T23:08:30.828340.gz\n",
      "./data/stream-2021-01-13T03:38:20.383129.gz\n",
      "./data/stream-2021-03-07T06:30:03.830030.gz\n",
      "./data/stream-2021-01-13T04:37:35.200990.gz\n",
      "./data/stream-2021-03-07T03:34:53.811604.gz\n",
      "./data/stream-2021-04-17T07:23:41.809159.gz\n",
      "./data/stream-2021-01-12T22:39:33.810384.gz\n",
      "./data/stream-2021-03-06T03:25:42.946878.gz\n",
      "./data/stream-2021-01-12T22:09:26.798946.gz\n",
      "./data/stream-2021-03-07T04:06:04.938654.gz\n",
      "./data/stream-2021-03-07T01:39:45.126113.gz\n",
      "./data/stream-2021-03-07T08:30:55.833881.gz\n",
      "./data/stream-2021-03-07T02:36:22.842559.gz\n",
      "./data/stream-2021-03-06T01:33:50.975776.gz\n",
      "./data/stream-2021-03-06T01:59:57.825571.gz\n",
      "./data/stream-2021-03-07T07:50:03.791977.gz\n",
      "./data/stream-2021-04-17T04:49:34.818794.gz\n",
      "./data/stream-2021-03-06T00:38:21.058969.gz\n",
      "./data/stream-2021-03-07T01:29:37.938029.gz\n",
      "./data/stream-2021-01-13T00:02:22.807571.gz\n",
      "./data/stream-2021-03-06T23:16:19.931951.gz\n",
      "./data/stream-2021-01-13T02:14:13.914215.gz\n",
      "./data/stream-2021-03-07T05:50:51.797120.gz\n",
      "./data/stream-2021-03-06T02:27:32.944437.gz\n",
      "./data/stream-2021-04-17T06:45:57.765273.gz\n",
      "./data/stream-2021-03-06T22:46:55.051822.gz\n",
      "./data/stream-2021-04-17T05:28:35.936895.gz\n",
      "./data/stream-2021-03-06T03:56:50.840797.gz\n",
      "./data/stream-2021-03-06T23:44:28.885165.gz\n",
      "./data/stream-2021-03-07T00:38:41.940824.gz\n",
      "./data/stream-2021-04-17T03:33:36.470062.gz\n",
      "./data/stream-2021-03-07T01:54:03.127902.gz\n",
      "./data/stream-2021-03-07T01:04:07.119423.gz\n",
      "./data/stream-2021-01-13T03:09:29.015229.gz\n",
      "./data/stream-2021-03-07T06:39:59.560376.gz\n",
      "./data/stream-2021-04-17T06:07:42.842366.gz\n",
      "./data/stream-2021-01-13T00:55:27.831486.gz\n",
      "./data/stream-2021-03-06T04:30:10.792693.gz\n",
      "./data/stream-2021-01-13T05:09:14.938774.gz\n",
      "./data/stream-2021-03-06T02:55:50.791026.gz\n",
      "./data/stream-2021-04-17T03:36:31.821630.gz\n",
      "./data/stream-2021-03-07T04:38:41.798997.gz\n",
      "./data/stream-2021-01-12T23:35:55.813786.gz\n",
      "./data/stream-2021-01-13T00:28:46.798948.gz\n",
      "./data/stream-2021-03-07T00:12:11.870181.gz\n",
      "./data/stream-2021-04-17T04:12:10.798493.gz\n",
      "./data/stream-2021-03-07T05:13:24.789931.gz\n",
      "./data/stream-2021-01-13T01:47:06.536491.gz\n",
      "./data/stream-2021-01-13T02:42:07.071964.gz\n"
     ]
    }
   ],
   "source": [
    "# filter testing and training data\n",
    "my_filter = filter.Filter(language)\n",
    "my_filter.filterData(\"./data/\")\n",
    "\n",
    "# split filtered data into two sets\n",
    "filtered_set_A = my_filter.getDataFrame().iloc[:int(len(my_filter.getDataFrame())/2)]\n",
    "filtered_set_B = my_filter.getDataFrame().iloc[int(len(my_filter.getDataFrame())/2):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0c114e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the cleanser\n",
    "my_cleanser = cleanse.Cleanser()\n",
    "\n",
    "# perform pre-processing on set B and save\n",
    "filtered_set_B[\"username\"] = filtered_set_B[\"username\"].apply(my_cleanser.transformUserName)\n",
    "filtered_set_B = filtered_set_B[['username','screen_name']]\n",
    "filtered_set_B.to_csv('filtered_set_B.txt', header=None, index=None, sep='\\t', mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9197fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define variables\n",
    "\n",
    "edit_threshold = 0.3\n",
    "edit_string = str(int(edit_threshold*100))\n",
    "model_name = 'model_A'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8593340f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cleansed names as: \n",
      "train_30_edit_distance_language_cleansed.txt 29606 number of rows. \n",
      "test1_cleansed.txt 174 number of rows. \n",
      "test2_cleansed.txt 234 number of rows. \n",
      "test3_cleansed.txt 481 number of rows. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# the split data is uncleansed btw\n",
    "my_cleanser.splitTrainTest(filtered_set_A)\n",
    "\n",
    "# this does the cleansing of the test datasets\n",
    "my_cleanser.createTestDataSets()\n",
    "# this does the cleansing of the training dataset\n",
    "my_cleanser.createTrainDataSet(edit_threshold = edit_threshold)\n",
    "# save cleansed test and train files\n",
    "my_cleanser.saveTestAndTrain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5cd06dae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique input tokens: 27\n",
      "Number of unique output tokens: 5071\n",
      "Max sequence length for inputs: 22\n",
      "Max sequence length for outputs: 52\n",
      "Epoch 1/10\n",
      "741/741 [==============================] - 624s 838ms/step - loss: 0.7746 - accuracy: 0.9045 - val_loss: 0.4098 - val_accuracy: 0.9269\n",
      "Epoch 2/10\n",
      "741/741 [==============================] - 620s 836ms/step - loss: 0.3910 - accuracy: 0.9287 - val_loss: 0.3778 - val_accuracy: 0.9290\n",
      "Epoch 3/10\n",
      "741/741 [==============================] - 592s 798ms/step - loss: 0.3455 - accuracy: 0.9344 - val_loss: 0.3227 - val_accuracy: 0.9388\n",
      "Epoch 4/10\n",
      "741/741 [==============================] - 592s 799ms/step - loss: 0.3000 - accuracy: 0.9426 - val_loss: 0.2850 - val_accuracy: 0.9456\n",
      "Epoch 5/10\n",
      "741/741 [==============================] - 593s 801ms/step - loss: 0.2631 - accuracy: 0.9498 - val_loss: 0.2563 - val_accuracy: 0.9520\n",
      "Epoch 6/10\n",
      "741/741 [==============================] - 588s 794ms/step - loss: 0.2405 - accuracy: 0.9543 - val_loss: 0.2388 - val_accuracy: 0.9557\n",
      "Epoch 7/10\n",
      "741/741 [==============================] - 574s 775ms/step - loss: 0.2222 - accuracy: 0.9581 - val_loss: 0.2298 - val_accuracy: 0.9575\n",
      "Epoch 8/10\n",
      "741/741 [==============================] - 585s 789ms/step - loss: 0.2067 - accuracy: 0.9609 - val_loss: 0.2238 - val_accuracy: 0.9582\n",
      "Epoch 9/10\n",
      "741/741 [==============================] - 577s 778ms/step - loss: 0.1940 - accuracy: 0.9634 - val_loss: 0.2166 - val_accuracy: 0.9600\n",
      "Epoch 10/10\n",
      "741/741 [==============================] - 573s 773ms/step - loss: 0.1820 - accuracy: 0.9656 - val_loss: 0.2126 - val_accuracy: 0.9606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
      "INFO:tensorflow:Assets written to: model_A/assets\n"
     ]
    }
   ],
   "source": [
    "# train model and save model 1\n",
    "trainer_and_tester = model_trainer_and_tester.ModelTrainerAndTester(\n",
    "    language=language, \n",
    "    epochs=10\n",
    ")\n",
    "trainer_and_tester.determineDimensions(['train_'+edit_string+'_edit_distance_language_cleansed.txt', 'test1_cleansed.txt', 'test2_cleansed.txt', 'test3_cleansed.txt', 'filtered_set_B.txt'])\n",
    "train_encode_input, train_decode_input, train_decode_output = trainer_and_tester.processData('train_'+edit_string+'_edit_distance_language_cleansed.txt')\n",
    "trainer_and_tester.buildModel()\n",
    "trainer_and_tester.trainModel(model_name, train_encode_input, train_decode_input, train_decode_output)\n",
    "trainer_and_tester.createDecoderEncoder(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "02ab1795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "evaluating on test set with 0 edit threshold...\n",
      "6/6 [==============================] - 2s 212ms/step - loss: 0.1217 - accuracy: 0.9772\n",
      "test loss, test acc: [0.1217440590262413, 0.9772325158119202]\n",
      "evaluating on test set with 0.1 edit threshold...\n",
      "8/8 [==============================] - 2s 225ms/step - loss: 0.1627 - accuracy: 0.9704\n",
      "test loss, test acc: [0.16271840035915375, 0.9704142212867737]\n",
      "evaluating on test set with 0.25 edit threshold...\n",
      "16/16 [==============================] - 4s 223ms/step - loss: 0.2012 - accuracy: 0.9619\n",
      "test loss, test acc: [0.201243057847023, 0.9618982672691345]\n"
     ]
    }
   ],
   "source": [
    "trainer_and_tester.evaluateOnTestData(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11879365",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3452cbf1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cafa23cd",
   "metadata": {},
   "source": [
    "# Reloading model A since it has already been trained on previous runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7a640af",
   "metadata": {},
   "outputs": [],
   "source": [
    "language = 'ja'\n",
    "import name_transliteration.model_trainer_and_tester as model_trainer_and_tester\n",
    "loaded_model = model_trainer_and_tester.ModelTrainerAndTester(\n",
    "    language=language\n",
    ")\n",
    "loaded_model.loadDataParameters()\n",
    "loaded_model.createDecoderEncoder('model_A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf6acebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "evaluating on test set with 0 edit threshold...\n",
      "6/6 [==============================] - 3s 244ms/step - loss: 0.1217 - accuracy: 0.9772\n",
      "test loss, test acc: [0.1217440590262413, 0.9772325158119202]\n",
      "evaluating on test set with 0.1 edit threshold...\n",
      "8/8 [==============================] - 3s 250ms/step - loss: 0.1627 - accuracy: 0.9704\n",
      "test loss, test acc: [0.16271840035915375, 0.9704142212867737]\n",
      "evaluating on test set with 0.25 edit threshold...\n",
      "16/16 [==============================] - 5s 253ms/step - loss: 0.2012 - accuracy: 0.9619\n",
      "test loss, test acc: [0.201243057847023, 0.9618982672691345]\n"
     ]
    }
   ],
   "source": [
    "loaded_model.evaluateOnTestData('model_A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "35df30ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the create_probabilities() method is reall memory intensive\n",
    "# it crashes when trying to predict files with over 20,000 rows\n",
    "# to solve this issue, we are going to split a large file into multiple ones each with only 20,000 rows\n",
    "\n",
    "lines_per_file = 20000\n",
    "smallfile = None\n",
    "total_lines = 0\n",
    "with open('filtered_set_B.txt') as bigfile:\n",
    "    for line_number, line in enumerate(bigfile):\n",
    "        if line_number % lines_per_file == 0:\n",
    "            if smallfile:\n",
    "                smallfile.close()\n",
    "            small_filename = 'filtered_set_B_{}.txt'.format(int(line_number/lines_per_file))\n",
    "            smallfile = open(small_filename, \"w\")\n",
    "        smallfile.write(line)\n",
    "        total_lines = total_lines + 1\n",
    "    if smallfile:\n",
    "        smallfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1065dded",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_runs = int(total_lines/20000)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868b3d45",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data is processed\n",
      "completed prediction iteration: 1 of 21\n",
      "completed prediction iteration: 2 of 21\n",
      "completed prediction iteration: 3 of 21\n",
      "completed prediction iteration: 4 of 21\n",
      "completed prediction iteration: 5 of 21\n",
      "completed prediction iteration: 6 of 21\n",
      "completed prediction iteration: 7 of 21\n",
      "completed prediction iteration: 8 of 21\n",
      "completed prediction iteration: 9 of 21\n",
      "completed prediction iteration: 10 of 21\n",
      "completed prediction iteration: 11 of 21\n",
      "completed prediction iteration: 12 of 21\n",
      "completed prediction iteration: 13 of 21\n",
      "completed prediction iteration: 14 of 21\n",
      "completed prediction iteration: 15 of 21\n",
      "completed prediction iteration: 16 of 21\n",
      "completed prediction iteration: 17 of 21\n",
      "completed prediction iteration: 18 of 21\n",
      "completed prediction iteration: 19 of 21\n",
      "completed prediction iteration: 20 of 21\n",
      "20000 predictions completed\n",
      "data is processed\n",
      "completed prediction iteration: 1 of 21\n",
      "completed prediction iteration: 2 of 21\n",
      "completed prediction iteration: 3 of 21\n",
      "completed prediction iteration: 4 of 21\n",
      "completed prediction iteration: 5 of 21\n",
      "completed prediction iteration: 6 of 21\n",
      "completed prediction iteration: 7 of 21\n",
      "completed prediction iteration: 8 of 21\n",
      "completed prediction iteration: 9 of 21\n",
      "completed prediction iteration: 10 of 21\n",
      "completed prediction iteration: 11 of 21\n",
      "completed prediction iteration: 12 of 21\n",
      "completed prediction iteration: 13 of 21\n",
      "completed prediction iteration: 14 of 21\n",
      "completed prediction iteration: 15 of 21\n",
      "completed prediction iteration: 16 of 21\n",
      "completed prediction iteration: 17 of 21\n",
      "completed prediction iteration: 18 of 21\n",
      "completed prediction iteration: 19 of 21\n",
      "completed prediction iteration: 20 of 21\n",
      "20000 predictions completed\n",
      "data is processed\n",
      "completed prediction iteration: 1 of 21\n",
      "completed prediction iteration: 2 of 21\n",
      "completed prediction iteration: 3 of 21\n",
      "completed prediction iteration: 4 of 21\n",
      "completed prediction iteration: 5 of 21\n",
      "completed prediction iteration: 6 of 21\n",
      "completed prediction iteration: 7 of 21\n",
      "completed prediction iteration: 8 of 21\n",
      "completed prediction iteration: 9 of 21\n",
      "completed prediction iteration: 10 of 21\n",
      "completed prediction iteration: 11 of 21\n",
      "completed prediction iteration: 12 of 21\n",
      "completed prediction iteration: 13 of 21\n",
      "completed prediction iteration: 14 of 21\n",
      "completed prediction iteration: 15 of 21\n"
     ]
    }
   ],
   "source": [
    "big_prob_list = []\n",
    "for i in range(total_runs):\n",
    "    prob_list = loaded_model.create_probabilities(\"filtered_set_B_{}.txt\".format(i))\n",
    "    big_prob_list.extend(prob_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d484570c",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data is processed\n",
      "completed prediction iteration: 1 of 21\n",
      "completed prediction iteration: 2 of 21\n",
      "completed prediction iteration: 3 of 21\n",
      "completed prediction iteration: 4 of 21\n",
      "completed prediction iteration: 5 of 21\n",
      "completed prediction iteration: 6 of 21\n",
      "completed prediction iteration: 7 of 21\n",
      "completed prediction iteration: 8 of 21\n",
      "completed prediction iteration: 9 of 21\n",
      "completed prediction iteration: 10 of 21\n",
      "completed prediction iteration: 11 of 21\n",
      "completed prediction iteration: 12 of 21\n",
      "completed prediction iteration: 13 of 21\n",
      "completed prediction iteration: 14 of 21\n",
      "completed prediction iteration: 15 of 21\n",
      "completed prediction iteration: 16 of 21\n",
      "completed prediction iteration: 17 of 21\n",
      "completed prediction iteration: 18 of 21\n",
      "completed prediction iteration: 19 of 21\n",
      "completed prediction iteration: 20 of 21\n",
      "20000 predictions completed\n",
      "CPU times: user 10min 48s, sys: 2min 45s, total: 13min 34s\n",
      "Wall time: 3min 30s\n"
     ]
    }
   ],
   "source": [
    "prob_list = []\n",
    "\n",
    "loaded_model.create_probabilities(\"filtered_set_B_small.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3574d65c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "filtered_set_B_small = pd.read_csv(\"filtered_set_B_small.txt\", sep='\\t', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5ae42c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "probability_threshold = 0.75\n",
    "drop_list = []\n",
    "for i, prob in enumerate(prob_list):\n",
    "    if prob <= probability_threshold:\n",
    "        drop_list.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d4713ff1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19968"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(drop_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7b906bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleansed_set_B_small = filtered_set_B_small.drop(drop_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c4bc8f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleansed_set_B_small.to_csv('cleansed_set_B_small.txt', header=None, index=None, sep='\\t', mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a9573a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bf8053d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1/1 [==============================] - 5s 5s/step - loss: 8.5300 - accuracy: 0.0000e+00 - val_loss: 8.4246 - val_accuracy: 0.9478\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 1s 843ms/step - loss: 8.4261 - accuracy: 0.9362 - val_loss: 7.2243 - val_accuracy: 0.9478\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 1s 752ms/step - loss: 7.2259 - accuracy: 0.9362 - val_loss: 4.7276 - val_accuracy: 0.9478\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 1s 1s/step - loss: 4.7397 - accuracy: 0.9362 - val_loss: 3.0267 - val_accuracy: 0.9478\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 1s 814ms/step - loss: 3.0447 - accuracy: 0.9362 - val_loss: 1.7828 - val_accuracy: 0.9478\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 1s 790ms/step - loss: 1.8037 - accuracy: 0.9362 - val_loss: 1.0615 - val_accuracy: 0.9478\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 1s 751ms/step - loss: 1.0894 - accuracy: 0.9362 - val_loss: 0.7252 - val_accuracy: 0.9478\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 1s 899ms/step - loss: 0.7546 - accuracy: 0.9362 - val_loss: 0.5648 - val_accuracy: 0.9478\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 1s 722ms/step - loss: 0.5886 - accuracy: 0.9362 - val_loss: 0.4757 - val_accuracy: 0.9478\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 1s 730ms/step - loss: 0.4946 - accuracy: 0.9362 - val_loss: 0.4193 - val_accuracy: 0.9478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_8_layer_call_and_return_conditional_losses, lstm_cell_8_layer_call_fn, lstm_cell_9_layer_call_and_return_conditional_losses, lstm_cell_9_layer_call_fn, lstm_cell_8_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_8_layer_call_and_return_conditional_losses, lstm_cell_8_layer_call_fn, lstm_cell_9_layer_call_and_return_conditional_losses, lstm_cell_9_layer_call_fn, lstm_cell_8_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_B/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_B/assets\n"
     ]
    }
   ],
   "source": [
    "# training model B\n",
    "model_B = model_trainer_and_tester.ModelTrainerAndTester(\n",
    "    language=language, \n",
    "    epochs=10\n",
    ")\n",
    "model_B.loadDataParameters()\n",
    "train_encode_input, train_decode_input, train_decode_output = model_B.processData('cleansed_set_B_small.txt')\n",
    "model_B.buildModel()\n",
    "model_B.trainModel('model_B', train_encode_input, train_decode_input, train_decode_output)\n",
    "model_B.createDecoderEncoder('model_B')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c5aaa5d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "evaluating on test set with 0 edit threshold...\n",
      "6/6 [==============================] - 2s 211ms/step - loss: 0.6919 - accuracy: 0.9164\n",
      "test loss, test acc: [0.6918842792510986, 0.9164456129074097]\n",
      "evaluating on test set with 0.1 edit threshold...\n",
      "8/8 [==============================] - 2s 213ms/step - loss: 0.7414 - accuracy: 0.9113\n",
      "test loss, test acc: [0.7413906455039978, 0.9113247990608215]\n",
      "evaluating on test set with 0.25 edit threshold...\n",
      "16/16 [==============================] - 4s 237ms/step - loss: 0.7879 - accuracy: 0.9071\n",
      "test loss, test acc: [0.7879423499107361, 0.9071245789527893]\n"
     ]
    }
   ],
   "source": [
    "model_B.evaluateOnTestData('model_B')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb46b22e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739c1105",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94514f84",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9982b5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "81d6db78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished predictions!\n"
     ]
    }
   ],
   "source": [
    "prob_list = trainer_and_tester.create_probabilities('small_names.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c630930a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def create_probabilities(data_path):\n",
    "    test_encoder_input, test_decoder_input, test_decoder_output = trainer_and_tester.processData(data_path)\n",
    "    prediction = trainer_and_tester.model.predict([test_encoder_input, test_decoder_input])\n",
    "    print(\"finished predictions!\")\n",
    "\n",
    "    # prediction is a three dimensional numpy array\n",
    "    # first dimension relatees to which row of the original data\n",
    "    # second dimension is the sequence dimension, length will be the max decoder length\n",
    "    # third dimension is a probability distribution, length will be the number of target tokens\n",
    "    prob_list = []\n",
    "    for row in prediction:\n",
    "        for time_step in row:\n",
    "            highest_prob_idx = np.argmax(time_step[:])\n",
    "            if trainer_and_tester.reverse_target_char_index[highest_prob_idx] == '\\n':\n",
    "                prob = max(time_step[:])\n",
    "                prob_list.append(prob)\n",
    "                break\n",
    "    return prob_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7d6196eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished predictions!\n"
     ]
    }
   ],
   "source": [
    "prob_list = create_probabilities('small_names.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "69c56b85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.17142753,\n",
       " 0.05898299,\n",
       " 0.27404648,\n",
       " 0.24443997,\n",
       " 0.8746748,\n",
       " 0.08803612,\n",
       " 0.59971315,\n",
       " 0.15099098,\n",
       " 0.36538252,\n",
       " 0.29847044,\n",
       " 0.020500638,\n",
       " 0.39464876,\n",
       " 0.092565365,\n",
       " 0.19886206,\n",
       " 0.08433535,\n",
       " 0.3660765,\n",
       " 0.40596545,\n",
       " 0.037862115,\n",
       " 0.09895991,\n",
       " 0.5024829,\n",
       " 0.12542808]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f6f2775b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('まままま\\n', 0.24569076)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer_and_tester.predict('amaimono no')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "84d32256",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer_and_tester.reverse_target_char_index[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f3ac20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2d7def6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8add3ec0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique input tokens: 27\n",
      "Number of unique output tokens: 937\n",
      "Max sequence length for inputs: 19\n",
      "Max sequence length for outputs: 43\n",
      "Epoch 1/20\n",
      "21/21 [==============================] - 6s 182ms/step - loss: 3.2954 - accuracy: 0.7149 - val_loss: 0.8984 - val_accuracy: 0.8613\n",
      "Epoch 2/20\n",
      "21/21 [==============================] - 3s 149ms/step - loss: 0.9094 - accuracy: 0.8595 - val_loss: 0.8778 - val_accuracy: 0.8625\n",
      "Epoch 3/20\n",
      "21/21 [==============================] - 4s 169ms/step - loss: 0.8777 - accuracy: 0.8636 - val_loss: 0.9020 - val_accuracy: 0.8635\n",
      "Epoch 4/20\n",
      "21/21 [==============================] - 3s 165ms/step - loss: 0.8133 - accuracy: 0.8684 - val_loss: 0.8771 - val_accuracy: 0.8633\n",
      "Epoch 5/20\n",
      "21/21 [==============================] - 4s 191ms/step - loss: 0.8245 - accuracy: 0.8665 - val_loss: 0.8873 - val_accuracy: 0.8640\n",
      "Epoch 6/20\n",
      "21/21 [==============================] - 3s 166ms/step - loss: 0.8412 - accuracy: 0.8631 - val_loss: 0.8771 - val_accuracy: 0.8633\n",
      "Epoch 7/20\n",
      "21/21 [==============================] - 3s 152ms/step - loss: 0.8309 - accuracy: 0.8655 - val_loss: 0.9061 - val_accuracy: 0.8639\n",
      "Epoch 8/20\n",
      "21/21 [==============================] - 3s 150ms/step - loss: 0.8227 - accuracy: 0.8676 - val_loss: 0.8578 - val_accuracy: 0.8677\n",
      "Epoch 9/20\n",
      "21/21 [==============================] - 3s 151ms/step - loss: 0.8346 - accuracy: 0.8595 - val_loss: 0.8484 - val_accuracy: 0.8723\n",
      "Epoch 10/20\n",
      "21/21 [==============================] - 3s 148ms/step - loss: 0.7462 - accuracy: 0.8726 - val_loss: 1.6527 - val_accuracy: 0.8820\n",
      "Epoch 11/20\n",
      "21/21 [==============================] - 4s 176ms/step - loss: 0.9149 - accuracy: 0.8697 - val_loss: 0.8482 - val_accuracy: 0.8663\n",
      "Epoch 12/20\n",
      "21/21 [==============================] - 4s 172ms/step - loss: 0.7779 - accuracy: 0.8691 - val_loss: 0.8195 - val_accuracy: 0.8747\n",
      "Epoch 13/20\n",
      "21/21 [==============================] - 4s 171ms/step - loss: 0.7367 - accuracy: 0.8731 - val_loss: 0.8318 - val_accuracy: 0.8692\n",
      "Epoch 14/20\n",
      "21/21 [==============================] - 3s 165ms/step - loss: 0.7354 - accuracy: 0.8732 - val_loss: 0.8281 - val_accuracy: 0.8789\n",
      "Epoch 15/20\n",
      "21/21 [==============================] - 4s 214ms/step - loss: 0.7838 - accuracy: 0.8735 - val_loss: 0.8077 - val_accuracy: 0.8797\n",
      "Epoch 16/20\n",
      "21/21 [==============================] - 3s 160ms/step - loss: 0.7104 - accuracy: 0.8771 - val_loss: 0.8145 - val_accuracy: 0.8779\n",
      "Epoch 17/20\n",
      "21/21 [==============================] - 3s 149ms/step - loss: 0.7405 - accuracy: 0.8704 - val_loss: 0.8135 - val_accuracy: 0.8812\n",
      "Epoch 18/20\n",
      "21/21 [==============================] - 3s 148ms/step - loss: 0.6861 - accuracy: 0.8789 - val_loss: 0.8326 - val_accuracy: 0.8824\n",
      "Epoch 19/20\n",
      "21/21 [==============================] - 3s 156ms/step - loss: 0.7475 - accuracy: 0.8661 - val_loss: 0.7993 - val_accuracy: 0.8823\n",
      "Epoch 20/20\n",
      "21/21 [==============================] - 3s 154ms/step - loss: 0.6678 - accuracy: 0.8820 - val_loss: 0.8000 - val_accuracy: 0.8814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_6_layer_call_and_return_conditional_losses, lstm_cell_6_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses, lstm_cell_7_layer_call_fn, lstm_cell_6_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_6_layer_call_and_return_conditional_losses, lstm_cell_6_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses, lstm_cell_7_layer_call_fn, lstm_cell_6_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
      "INFO:tensorflow:Assets written to: ja_model_20_v2/assets\n"
     ]
    }
   ],
   "source": [
    "# train model 2 and save model 2\n",
    "trainer_and_tester2 = model_trainer_and_tester.ModelTrainerAndTester(\n",
    "    language=language, \n",
    "    epochs=20\n",
    ")\n",
    "# trainer_and_tester2.determineDimensions(['train_10_edit_distance_language_cleansed.txt', 'test1_cleansed.txt', 'test2_cleansed.txt', 'test3_cleansed.txt', 'filtered_set_B.txt','model_cleansed_names.txt'])\n",
    "# train_encode_input, train_decode_input, train_decode_output = trainer_and_tester2.processData('model_cleansed_names.txt')\n",
    "# trainer_and_tester2.buildModel()\n",
    "# trainer_and_tester2.trainModel(language + '_model_'+str(20)+'_v2', train_encode_input, train_decode_input, train_decode_output)\n",
    "# trainer_and_tester2.createDecoderEncoder(language + '_model_'+str(20)+'_v2')\n",
    "\n",
    "trainer_and_tester2.runWholeTrainProcess('model_cleansed_names.txt', 'model_20_v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3011e7ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "evaluating on test set with 0 edit threshold...\n",
      "5/5 [==============================] - 1s 51ms/step - loss: 0.4885 - accuracy: 0.9236\n",
      "test loss, test acc: [0.4885435402393341, 0.9235658645629883]\n",
      "evaluating on test set with 0.1 edit threshold...\n",
      "7/7 [==============================] - 0s 57ms/step - loss: 0.5423 - accuracy: 0.9160\n",
      "test loss, test acc: [0.5423395037651062, 0.91595458984375]\n",
      "evaluating on test set with 0.25 edit threshold...\n",
      "14/14 [==============================] - 1s 52ms/step - loss: 0.5509 - accuracy: 0.9147\n",
      "test loss, test acc: [0.5509322285652161, 0.9147106409072876]\n"
     ]
    }
   ],
   "source": [
    "trainer_and_tester2.evaluateOnTestData('model_'+str(20)+'_v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "31be838f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('あくち\\n', 0.22617334)\n",
      "('お\\n', 0.0751004)\n"
     ]
    }
   ],
   "source": [
    "print(trainer_and_tester.predict('reiwatomo'))\n",
    "print(trainer_and_tester2.predict('reiwatomo'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d15fe059",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set_A = my_cleanser.training_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f14e4d2f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>username</th>\n",
       "      <th>screen_name</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>amaimono no</td>\n",
       "      <td>甘いもの</td>\n",
       "      <td>ja</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33</td>\n",
       "      <td>animejikkyobot</td>\n",
       "      <td>アニメ実況</td>\n",
       "      <td>ja</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>42</td>\n",
       "      <td>tsudayan</td>\n",
       "      <td>つだやん</td>\n",
       "      <td>ja</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47</td>\n",
       "      <td>ayu ko</td>\n",
       "      <td>鮎子</td>\n",
       "      <td>ja</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>63</td>\n",
       "      <td>mashiroharu</td>\n",
       "      <td>ましろはる</td>\n",
       "      <td>ja</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2295</th>\n",
       "      <td>25766</td>\n",
       "      <td>future</td>\n",
       "      <td>ふつれ</td>\n",
       "      <td>ja</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2296</th>\n",
       "      <td>25786</td>\n",
       "      <td>ri o</td>\n",
       "      <td>りお</td>\n",
       "      <td>ja</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2297</th>\n",
       "      <td>25791</td>\n",
       "      <td>future</td>\n",
       "      <td>ふつれ</td>\n",
       "      <td>ja</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2298</th>\n",
       "      <td>25804</td>\n",
       "      <td>paprikasan</td>\n",
       "      <td>パプリカ</td>\n",
       "      <td>ja</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2299</th>\n",
       "      <td>25808</td>\n",
       "      <td>zigo aku</td>\n",
       "      <td>じごあく</td>\n",
       "      <td>ja</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2300 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index        username screen_name language\n",
       "0        10     amaimono no        甘いもの       ja\n",
       "1        33  animejikkyobot       アニメ実況       ja\n",
       "2        42        tsudayan        つだやん       ja\n",
       "3        47          ayu ko          鮎子       ja\n",
       "4        63     mashiroharu       ましろはる       ja\n",
       "...     ...             ...         ...      ...\n",
       "2295  25766          future         ふつれ       ja\n",
       "2296  25786            ri o          りお       ja\n",
       "2297  25791          future         ふつれ       ja\n",
       "2298  25804      paprikasan        パプリカ       ja\n",
       "2299  25808        zigo aku        じごあく       ja\n",
       "\n",
       "[2300 rows x 4 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aca1b6bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('お\\n', 0.07910247)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer_and_tester2.predict('zigo aku')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "705dd48d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-732443efe440>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtraining_set_A\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"conf\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_set_A\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"username\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict_confidence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer_and_tester2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/name-transliteration-sfy7S-9L-py3.8/lib/python3.8/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m   4136\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4137\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4138\u001b[0;31m                 \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4140\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/name-transliteration-sfy7S-9L-py3.8/lib/python3.8/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mf\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   4121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4122\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4123\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4125\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-c9b1203a3f04>\u001b[0m in \u001b[0;36mpredict_confidence\u001b[0;34m(name, model_class)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpredict_confidence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_class\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mconf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/name_transliteration/name_transliteration/model_trainer_and_tester.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    298\u001b[0m         \u001b[0;31m# from when the sequence ends, we have to fill up the rest with spaces\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m         \u001b[0mone_hot_vector\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msequence_end\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_token_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mone_hot_vector\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbatch_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist_of_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/name_transliteration/name_transliteration/model_trainer_and_tester.py\u001b[0m in \u001b[0;36mdecode_sequence\u001b[0;34m(self, input_seq)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m             \u001b[0;31m# see if output_tokens are probabilties from softmax\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m             \u001b[0moutput_tokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget_seq\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstates_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m             \u001b[0;31m# print(\"output_tokens: \" + str(output_tokens))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m             \u001b[0;31m# print(\"h: \" + str(h))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/name-transliteration-sfy7S-9L-py3.8/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1623\u001b[0m       \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1624\u001b[0m       \u001b[0mbatch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1625\u001b[0;31m       \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menumerate_epochs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Single epoch.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1626\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_stop_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1627\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/name-transliteration-sfy7S-9L-py3.8/lib/python3.8/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36menumerate_epochs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1131\u001b[0m     \u001b[0;34m\"\"\"Yields `(epoch, tf.data.Iterator)`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_truncate_execution_to_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1133\u001b[0;31m       \u001b[0mdata_iterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1134\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initial_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1135\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_insufficient_data\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Set by `catch_stop_iteration`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/name-transliteration-sfy7S-9L-py3.8/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    420\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minside_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolocate_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 422\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0miterator_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOwnedIterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    423\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m       raise RuntimeError(\"__iter__() is only supported inside of tf.function \"\n",
      "\u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/name-transliteration-sfy7S-9L-py3.8/lib/python3.8/site-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset, components, element_spec)\u001b[0m\n\u001b[1;32m    680\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcomponents\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0melement_spec\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    681\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_message\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 682\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    683\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_create_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/name-transliteration-sfy7S-9L-py3.8/lib/python3.8/site-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_create_iterator\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    703\u001b[0m               \u001b[0moutput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_output_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m               output_shapes=self._flat_output_shapes))\n\u001b[0;32m--> 705\u001b[0;31m       \u001b[0mgen_dataset_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_variant\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    706\u001b[0m       \u001b[0;31m# Delete the resource when this object is deleted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m       self._resource_deleter = IteratorResourceDeleter(\n",
      "\u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/name-transliteration-sfy7S-9L-py3.8/lib/python3.8/site-packages/tensorflow/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36mmake_iterator\u001b[0;34m(dataset, iterator, name)\u001b[0m\n\u001b[1;32m   2969\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2970\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2971\u001b[0;31m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[1;32m   2972\u001b[0m         _ctx, \"MakeIterator\", name, dataset, iterator)\n\u001b[1;32m   2973\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "training_set_A[\"conf\"] = training_set_A[\"username\"].apply(predict_confidence, args=(trainer_and_tester2,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "732eb2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_encoder_input, test_decoder_input, test_decoder_output = trainer_and_tester.processData('small_names.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ab298875",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 1., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.]]], dtype=float32)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_encoder_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0a5d422d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = trainer_and_tester.model.predict([test_encoder_input, test_decoder_input])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "44dd83c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.functional.Functional at 0x182e7bf40>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer_and_tester.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "edaccf06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('あくち\\n', 0.16680214)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer_and_tester.predict(\"oharafumi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "b693bc42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' '"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer_and_tester.reverse_target_char_index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "ef6fd485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n",
      "42\n",
      "42\n",
      "42\n",
      "42\n",
      "42\n",
      "42\n"
     ]
    }
   ],
   "source": [
    "prob_list = []\n",
    "for i in range(len(prediction)):\n",
    "    char_idx = np.argmax(prediction[i,0,:])\n",
    "    print(char_idx)\n",
    "#     j = 1\n",
    "#     while char_idx != 0:\n",
    "#         char_idx = np.argmax(prediction[i,j,:])\n",
    "#         print(char_idx)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "1578633a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9899092"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction[0,5,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6b1a8384",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[8.3742070e-06, 1.4098549e-06, 6.5861754e-03, ...,\n",
       "         1.3929487e-06, 1.3458267e-06, 1.3111600e-06],\n",
       "        [3.7974369e-04, 8.7453395e-07, 1.7892161e-02, ...,\n",
       "         9.0219305e-07, 9.1668733e-07, 8.6946778e-07],\n",
       "        [2.0483108e-03, 5.9531010e-07, 1.1048008e-02, ...,\n",
       "         6.6449655e-07, 6.2310545e-07, 5.8859285e-07],\n",
       "        ...,\n",
       "        [9.9999952e-01, 3.4604161e-13, 2.7603728e-10, ...,\n",
       "         3.6542796e-13, 3.3970927e-13, 3.3975074e-13],\n",
       "        [9.9999952e-01, 3.4598550e-13, 2.7601357e-10, ...,\n",
       "         3.6530045e-13, 3.3962506e-13, 3.3969501e-13],\n",
       "        [9.9999952e-01, 3.4592481e-13, 2.7598673e-10, ...,\n",
       "         3.6517507e-13, 3.3954084e-13, 3.3963864e-13]],\n",
       "\n",
       "       [[2.5005045e-03, 2.6287576e-06, 3.9306772e-03, ...,\n",
       "         2.6972739e-06, 2.8987240e-06, 2.6490445e-06],\n",
       "        [2.5983499e-02, 9.0083904e-07, 4.4184611e-03, ...,\n",
       "         7.9166932e-07, 9.6195356e-07, 8.6236685e-07],\n",
       "        [1.4645259e-01, 3.5979941e-08, 3.9797407e-04, ...,\n",
       "         3.7502524e-08, 3.5116646e-08, 3.3525097e-08],\n",
       "        ...,\n",
       "        [9.9999952e-01, 3.4706813e-13, 2.7686564e-10, ...,\n",
       "         3.6636663e-13, 3.4048640e-13, 3.4060981e-13],\n",
       "        [9.9999952e-01, 3.4689607e-13, 2.7674421e-10, ...,\n",
       "         3.6612773e-13, 3.4030981e-13, 3.4045523e-13],\n",
       "        [9.9999952e-01, 3.4672807e-13, 2.7662705e-10, ...,\n",
       "         3.6589945e-13, 3.4014236e-13, 3.4030461e-13]],\n",
       "\n",
       "       [[5.9916871e-05, 8.8301732e-07, 5.4043503e-03, ...,\n",
       "         9.2981742e-07, 9.1482065e-07, 8.9488253e-07],\n",
       "        [1.7532542e-03, 1.0315242e-06, 1.2150825e-02, ...,\n",
       "         1.0203256e-06, 1.1280154e-06, 1.0877491e-06],\n",
       "        [1.5475099e-02, 5.8179762e-07, 3.8177771e-03, ...,\n",
       "         5.5789059e-07, 5.8100142e-07, 5.5304406e-07],\n",
       "        ...,\n",
       "        [9.9999952e-01, 3.4595251e-13, 2.7576416e-10, ...,\n",
       "         3.6526213e-13, 3.3953954e-13, 3.3954732e-13],\n",
       "        [9.9999952e-01, 3.4588654e-13, 2.7574629e-10, ...,\n",
       "         3.6513327e-13, 3.3945150e-13, 3.3949292e-13],\n",
       "        [9.9999952e-01, 3.4582190e-13, 2.7572419e-10, ...,\n",
       "         3.6500794e-13, 3.3937122e-13, 3.3943725e-13]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[7.4665826e-05, 9.5655628e-07, 5.2526542e-03, ...,\n",
       "         1.0129500e-06, 9.9195859e-07, 9.6561746e-07],\n",
       "        [1.9087842e-03, 5.8118832e-07, 1.1744892e-02, ...,\n",
       "         5.5921072e-07, 6.1442478e-07, 5.9101899e-07],\n",
       "        [7.7273999e-03, 1.8179801e-07, 2.8671452e-03, ...,\n",
       "         1.6821602e-07, 1.7253787e-07, 1.6646695e-07],\n",
       "        ...,\n",
       "        [9.9999952e-01, 3.4533940e-13, 2.7530012e-10, ...,\n",
       "         3.6466069e-13, 3.3910656e-13, 3.3900763e-13],\n",
       "        [9.9999952e-01, 3.4531438e-13, 2.7530853e-10, ...,\n",
       "         3.6457165e-13, 3.3904644e-13, 3.3898952e-13],\n",
       "        [9.9999952e-01, 3.4528738e-13, 2.7531480e-10, ...,\n",
       "         3.6448684e-13, 3.3898952e-13, 3.3896882e-13]],\n",
       "\n",
       "       [[2.7110751e-05, 1.0695640e-06, 5.9167799e-03, ...,\n",
       "         1.1107491e-06, 1.1118333e-06, 1.0811607e-06],\n",
       "        [1.2681487e-03, 7.8571412e-07, 1.4341043e-02, ...,\n",
       "         7.8367941e-07, 8.3146631e-07, 8.2461895e-07],\n",
       "        [2.9130777e-02, 5.4423839e-07, 4.1661048e-03, ...,\n",
       "         5.2917784e-07, 5.4217918e-07, 5.1850975e-07],\n",
       "        ...,\n",
       "        [9.9999952e-01, 3.4473788e-13, 2.7455757e-10, ...,\n",
       "         3.6408384e-13, 3.3849654e-13, 3.3832035e-13],\n",
       "        [9.9999952e-01, 3.4474512e-13, 2.7460628e-10, ...,\n",
       "         3.6402484e-13, 3.3847138e-13, 3.3833580e-13],\n",
       "        [9.9999952e-01, 3.4474710e-13, 2.7464767e-10, ...,\n",
       "         3.6396512e-13, 3.3844555e-13, 3.3835001e-13]],\n",
       "\n",
       "       [[6.4835406e-04, 1.6627907e-06, 4.2302022e-03, ...,\n",
       "         1.8080917e-06, 1.8071626e-06, 1.6973597e-06],\n",
       "        [6.8034385e-03, 9.8094381e-07, 6.7668692e-03, ...,\n",
       "         8.5611106e-07, 1.0272706e-06, 9.2693381e-07],\n",
       "        [1.1402255e-02, 3.9520316e-08, 5.5941002e-04, ...,\n",
       "         3.7613788e-08, 3.6400458e-08, 3.5061372e-08],\n",
       "        ...,\n",
       "        [9.9999952e-01, 3.4600136e-13, 2.7591990e-10, ...,\n",
       "         3.6524402e-13, 3.3963219e-13, 3.3965419e-13],\n",
       "        [9.9999952e-01, 3.4591427e-13, 2.7587252e-10, ...,\n",
       "         3.6509635e-13, 3.3952401e-13, 3.3957453e-13],\n",
       "        [9.9999952e-01, 3.4582718e-13, 2.7582517e-10, ...,\n",
       "         3.6495432e-13, 3.3942171e-13, 3.3949682e-13]]], dtype=float32)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "12bb0f5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, None, 27)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None, 2972)] 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 256), (None, 290816      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, None, 256),  3306496     input_2[0][0]                    \n",
      "                                                                 lstm[0][1]                       \n",
      "                                                                 lstm[0][2]                       \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, None, 2972)   763804      lstm_1[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 4,361,116\n",
      "Trainable params: 4,361,116\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "trainer_and_tester.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7eef0a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
