{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be824b86",
   "metadata": {},
   "source": [
    "this notebook is for plotting out graphs and exploring the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b85f139a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0dce4736",
   "metadata": {},
   "outputs": [],
   "source": [
    "language = 'ja'\n",
    "import name_transliteration.filtering as filter\n",
    "import name_transliteration.cleansing as cleanse\n",
    "import name_transliteration.model_trainer_and_tester as model_trainer_and_tester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b44afa0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/stream-2021-03-07T03:05:07.831679.gz\n",
      "./data/stream-2021-01-13T01:21:29.804195.gz\n",
      "./data/stream-2021-01-13T04:07:46.253913.gz\n"
     ]
    }
   ],
   "source": [
    "# filter testing and training data\n",
    "my_filter = filter.Filter(language)\n",
    "my_filter.filterData(\"./data/\",3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7300745d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the cleanser\n",
    "my_cleanser = cleanse.Cleanser()\n",
    "\n",
    "raw_names = my_filter.getDataFrame()\n",
    "\n",
    "raw_names[\"username\"] = raw_names[\"username\"].apply(my_cleanser.transformUserName)\n",
    "raw_names = raw_names[['username','screen_name']]\n",
    "raw_names.to_csv('raw_names.txt', header=None, index=None, sep='\\t', mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "020aa350",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "loaded_model = model_trainer_and_tester.ModelTrainerAndTester(\n",
    "    language=language\n",
    ")\n",
    "loaded_model.loadDataParameters()\n",
    "loaded_model.createDecoderEncoder('model_A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "414744f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input, decoder_input, decoder_output = loaded_model.processData('raw_names.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f96ebf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27357"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(encoder_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a273bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed prediction iteration: 1 of 28\n",
      "completed prediction iteration: 2 of 28\n",
      "completed prediction iteration: 3 of 28\n",
      "completed prediction iteration: 4 of 28\n",
      "completed prediction iteration: 5 of 28\n",
      "completed prediction iteration: 6 of 28\n",
      "completed prediction iteration: 7 of 28\n",
      "completed prediction iteration: 8 of 28\n",
      "completed prediction iteration: 9 of 28\n",
      "completed prediction iteration: 10 of 28\n",
      "completed prediction iteration: 11 of 28\n",
      "completed prediction iteration: 12 of 28\n",
      "completed prediction iteration: 13 of 28\n",
      "completed prediction iteration: 14 of 28\n",
      "completed prediction iteration: 15 of 28\n",
      "completed prediction iteration: 16 of 28\n",
      "completed prediction iteration: 17 of 28\n",
      "completed prediction iteration: 18 of 28\n",
      "completed prediction iteration: 19 of 28\n",
      "completed prediction iteration: 20 of 28\n",
      "completed prediction iteration: 21 of 28\n"
     ]
    }
   ],
   "source": [
    "prediction_list = []\n",
    "\n",
    "# figure out how many runs it will take\n",
    "num_runs = int(len(encoder_input) / 1000) + 1\n",
    "\n",
    "for i in range(num_runs+1):\n",
    "    # ummm it crashes when it gets to here\n",
    "    if i == 21:\n",
    "        break\n",
    "    if i != 0:\n",
    "        slice_range_start = (i-1)*1000\n",
    "        slice_range_finish = i*1000\n",
    "        prediction = loaded_model.model.predict(\n",
    "            [encoder_input[slice_range_start:slice_range_finish], \n",
    "             decoder_input[slice_range_start:slice_range_finish]])\n",
    "        K.clear_session()\n",
    "        _ = gc.collect()\n",
    "        prediction_list.extend(prediction)\n",
    "        print(\"completed prediction iteration: \" + str(i) + \" of \" + str(num_runs))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e51ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(prediction_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81bfe5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "prob_list = []\n",
    "for row in prediction_list:\n",
    "    for time_step in row:\n",
    "        highest_prob_idx = np.argmax(time_step[:])\n",
    "        if loaded_model.reverse_target_char_index[highest_prob_idx] == '\\n':\n",
    "            prob = max(time_step[:])\n",
    "            prob_list.append(prob)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61fd0edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(np.array(prob_list), bins='auto')\n",
    "plt.title('Probability distribution over un-cleansed data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96505c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleansed_data = my_cleanser.cleanseData(my_filter.getDataFrame(), edit_threshold=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4ebe3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleansed_data = cleansed_data[['username','screen_name']]\n",
    "cleansed_data.to_csv('cleansed_names.txt', header=None, index=None, sep='\\t', mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3732c353",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input, decoder_input, decoder_output = loaded_model.processData('cleansed_names.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e62bdf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_list = []\n",
    "\n",
    "# figure out how many runs it will take\n",
    "num_runs = int(len(encoder_input) / 1000) + 1\n",
    "\n",
    "for i in range(num_runs+1):\n",
    "    if i != 0:\n",
    "        slice_range_start = (i-1)*1000\n",
    "        slice_range_finish = i*1000\n",
    "        prediction = loaded_model.model.predict(\n",
    "            [encoder_input[slice_range_start:slice_range_finish], \n",
    "             decoder_input[slice_range_start:slice_range_finish]])\n",
    "        prediction_list.extend(prediction)\n",
    "        print(\"completed prediction iteration: \" + str(i) + \" of \" + str(num_runs))\n",
    "prob_list = []\n",
    "for row in prediction_list:\n",
    "    for time_step in row:\n",
    "        highest_prob_idx = np.argmax(time_step[:])\n",
    "        if loaded_model.reverse_target_char_index[highest_prob_idx] == '\\n':\n",
    "            prob = max(time_step[:])\n",
    "            prob_list.append(prob)\n",
    "            break\n",
    "plt.hist(np.array(prob_list), bins='auto')\n",
    "plt.title('Probability distribution over cleansed data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5585e49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de5e68a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
